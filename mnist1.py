# -*- coding: utf-8 -*-
"""mnist1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z35V9bHAol0T8qIrdnN5cOBHT0_ILlSP
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score
# %matplotlib inline

from sklearn.datasets import fetch_openml
mnist = fetch_openml('mnist_784', version=1)
mnist.keys()

x = mnist['data'].values
y = mnist['target'].values

a = x[1]

a.shape

a1 = a.reshape(28,28)
a1.shape

plt.gray()
plt.matshow(a1)

y = y.astype(np.uint8)

x_train, x_test, y_train, y_test = x[:60000], x[60000::], y[:60000], y[60000::]

from sklearn.linear_model import SGDClassifier
sc = SGDClassifier(random_state=42)
sc.fit(x_train, y_train)

sc.predict([a])

some_digit_scores = sc.decision_function([a])
r = np.where(some_digit_scores == max(some_digit_scores))[0][0]
r, some_digit_scores

from sklearn.multiclass import OneVsOneClassifier
ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))
ovo_clf.fit(x_train, y_train)
ovo_clf.predict([a])

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(random_state=42)
rf.fit(x_train, y_train)

rf.predict([a])

rf.predict_proba([a])

cross_val_score(sc, x_train, y_train, cv=3, scoring="accuracy")

from sklearn.preprocessing import StandardScaler
scl = StandardScaler()
x_train_scaled = scl.fit_transform(x_train.astype(np.float64))
cross_val_score(sc, x_train, y_train, cv=3, scoring="accuracy")

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix

yp = cross_val_predict(sc, x_train_scaled, y_train, cv=3)
cm3 = confusion_matrix(y_train, yp)
cm3

sns.set(rc={'figure.figsize':(12,10)})
sns.heatmap(cm3, annot=True, cmap="RdBu")

row_sums = cm3.sum(axis=1, keepdims=True)
norm_cm = cm3 / row_sums

np.fill_diagonal(norm_cm, 0)
sns.heatmap(norm_cm, annot=True, cmap="RdBu")

cl_a, cl_b = 3, 5
x_aa = x_train[(y_train == cl_a) & (yp == cl_a)]
x_ab = x_train[(y_train == cl_a) & (yp == cl_b)]
x_ba = x_train[(y_train == cl_b) & (yp == cl_a)]
x_bb = x_train[(y_train == cl_b) & (yp == cl_b)]

def plot_digits(instances, images_per_row=10, **options):
    size = 28
    images_per_row = min(len(instances), images_per_row)
    images = [instance.reshape(size,size) for instance in instances]

    ########
    if images_per_row == 0:
       images_per_row = 0.1
    else:
        images_per_row = images_per_row
        pass
    ########

    n_rows = (len(instances) - 1) // images_per_row + 1
    row_images = []
    n_empty = n_rows * images_per_row - len(instances)
    images.append(np.zeros((size, size * n_empty)))
    for row in range(n_rows):
        rimages = images[row * images_per_row : (row + 1) * images_per_row]
        row_images.append(np.concatenate(rimages, axis=1))
    image = np.concatenate(row_images, axis=0)
    plt.imshow(image, cmap = plt.cm.binary, **options)
    plt.axis("off")

plt.figure(figsize=(8,8))
plt.subplot(221); plot_digits(x_aa[:25], images_per_row=5)
plt.subplot(222); plot_digits(x_ab[:25], images_per_row=5)
plt.subplot(223); plot_digits(x_ba[:25], images_per_row=5)
plt.subplot(224); plot_digits(x_bb[:25], images_per_row=5)
plt.show()

from sklearn.neighbors import KNeighborsClassifier
y_train_large = (y_train >= 7)
y_train_odd = (y_train % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]
knn_cl = KNeighborsClassifier()
knn_cl.fit(x_train, y_multilabel)

knn_cl.predict([a])

from sklearn.metrics import f1_score

y_train_knn_pred = cross_val_predict(knn_cl, x_train, y_multilabel, cv=3)
f1_score(y_multilabel, y_train_knn_pred, average="macro")

noise = np.random.randint(0, 100, (len(x_train), 784))
x_train_mod = x_train + noise
noise = np.random.randint(0, 100, (len(x_test), 784))
x_test_mod = x_test + noise
y_train_mod = x_train
y_test_mod = x_test

# the number after filled with noise
plt.gray()
b = x_test_mod[7]
b = b.reshape(28,28)
plt.matshow(b)

knn_cl.fit(x_train_mod, y_train_mod)
clean_digit = knn_cl.predict([x_test_mod[7]])
plot_digits(clean_digit)

import pickle as pk
pk.dump(sc, open('model.pkl', 'wb'))

mod = pk.load(open('model.pkl', 'rb'))
mod.predict([a])[0]

